\documentclass[
	%a4paper, % Use A4 paper size
	letterpaper, % Use US letter paper size
]{jdf}

\addbibresource{references.bib}
% Define custom command for parentheses citation
\newcommand{\pcite}[1]{(\cite{#1})}

\author{William Luna}
\email{wluna6@gatech.edu}
\title{Qualifier Question}

\begin{document}
%\lsstyle

\maketitle
%INSTRUCTIONS
%Before you can move on to proposing a contribution to the educational technology community, you need to demonstrate your mastery of the portion of the field to which you want to contribute. Because everyone’s interests and project ideas will be different, there is no question we can ask everyone that will be simultaneously deep enough to be challenging and general enough to cover everyone.

%So instead, on or by Friday of week 3, your mentor will send you a personal qualifier question targeted specifically to what you wrote on the first few assignments. This question will ask you to think deeply about the topics you have chosen. For the research track, it might ask you to synthesize and describe the viewpoints of different communities or research methodologies on your ideas. For the development track, it might ask you to describe the broader issues or pedagogical challenges associated with your intended designs. For the content track, it might ask you to consider elements of pedagogy and or instruction you have not yet considered.

%The primary goal of this assignment is to demonstrate your mastery of the portion of the field to which you want to contribute. In simpler words, the primary goal of this assignment is to show off what you know and how you can think. This is the closest thing this class has to a test. Adequately completing this assignment will require a significant command over the literature on your topic (in other words, several citations to others’ work in your area).

%Your assignment should be approximately 4 pages long in JDF. This is neither a minimum nor a maximum, but rather a heuristic to simply describe the level of depth we would like to see. Feel free to write more, or if you believe you can complete the assignment in fewer words, feel free to write less. Please make sure to include the question text itself so that your peer reviews know what you were asked to answer.

\section{Question}

\blockquote{Leveled\footnote{The response will consider leveled and graded readers to be interchangeable terms, but noting that literature occasionally cleaves a distinction between the former's tendency to refer to readers that facilitate primary school students learning to read in their native language, and the latter's tendency to facilitate learning a foreign language through reading. Since there is evidence to suggest that learning to read in one's native language involved mostly learning to read already-known words \pcite{hu_2000}, as opposed to encountering a larger percentage of unknown words when reading in a foreign language, the distinction can have pedagogical implications, although they have limited bearing on this response. This statement will focus on the \textit{latter} use case, creating reading material for students of a foreign language.} readers have been a standard feature of K12 education for years and many best practices have developed over time.  What does the literature suggest are those principles/practices (eg. introducing more complex words and constructions in a controlled sequence and avoiding their use prior to that introduction)? How can an LLM best be induced to follow these practices?}

\section{Response}

\subsection{Leveled readers have been a standard feature of K12 education for years and many best practices have developed over time.  What does the literature suggest are those principles and/or practices?}

While there has been considerable evolution in the learning science underpinning the use of leveled readers, few would argue the impact of Stephen Krashen's Applied Linguistics research. In particular, Krashen's theory of Massive Comprehensible Input laid a foundational argument that language is acquired most effectively by asking students to reach just beyond their current semantic and grammatical ability when ingesting written and spoken language, sometimes referred to as "i+1" \pcite{krashen1982principles, krashenreview}. A more direct (and less academic) version of this takeaway is the perhaps intuitive observation that time spent free reading correlates to overall literacy \pcite{krashen_2004}. A few years before Krashen's seminal paper, Lev Vygotsky coined the term Zone of Proximal Development, in many ways representing the culmination of his decades of research into child development. ZPD is too general a concept to be considered an analogy for Krashen's more specific theories of language acquisition, but is certainly an influential precursor \pcite{vygotsky, vygostky_krashen_not_same}.

However, these theories stop short of providing an objective measure of \textit{comprehensible}. How much novel vocabulary and grammar can a text present to a student without sacrificing their reading comprehension? Evidence shows that comprehension begins to dip if the percent of known words in a text falls below ninety-eight percent \pcite{hu_2000}. Unfortunately, this is a tall order for beginning and intermediate students. Ninety-eight percent comprehension of the words in young adult fiction requires knowing the 5,000 most common words in English \pcite{nation1992vocabulary}, which the Foreign Service Institute estimates requires a minimum of six hundred hours of study \pcite{fsi_language_learning}. Given that most American public high schools have one-hundred eighty days of instruction in a year, a student who begins a foreign language their freshman year, studying an hour each school day for all four years of high school, would fail to reach this level by the time they graduate.

The above hypothetical demonstrates the need for leveled readers, but what are the best practices for creating them? For one, fiction is a superior candidate for leveled readers, since uncommon words occur at a lower frequency in fiction that non-fiction \pcite{hu_2000}. Since students read for longer periods of time when interested in the subject matter, it's important to provide a variety of reading material that caters to each student's interests. \pcite{llm_augmented_exercise_retrieval}. Research has also shown that simplified reading material can lose too much nuance when simplified below the 2,500 most common words of a language, implying that leveled readers are difficult to introduce until a student has reached an advanced beginner proficiency in the foreign language \pcite{nation1992vocabulary}. 

Besides the general notion of producing a work of fiction-or simplifying an existing one–to a student's current understanding of syntax, semantics, and lexicon, is it possible to identify more specific guiding best practices? One such recommendation is to present specific vocabulary in the text enough times to commit it into memory. The fact that the more an individual encounters a word the more likely they are to remember it has been proven empirically \pcite{clockworkorange}, where a word has to be encountered an average of ten times before being cemented into long-term memory \pcite{Nation2020GradedRA} with continuous exposure to avoid forgetting it \pcite{cepedasrs}.

Independently of frequency, extensive research has been done into the optimal interval of time between presenting repetition of a word being studied by a language learner. Ebbinghaus' Forgetting Curve has been replicated several times since it was initially proposed in the late 1800s \pcite{Murre2015ReplicationAA}. It proposes that human memory mimics a logarithmic function, where an entirely novel piece of information is quickly forgotten unless promptly recalled, and that more time can pass between each subsequent recall of that information before forgetting it. This finding implies that a leveled reader would be most effective if it repeated newly learned words in its text on deliberate intervals that followed the Forgetting Curve \pcite{shortestpathrepetitionscheduling}.

Dictionary use is another critical topic when discussing leveled readers. Should a student reference a dictionary at all when engaged in free extensive reading? If so, how? What is the ideal format of that dictionary? One study suggests that vocabulary retention is greatest in a "passive-first" environment, where dictionaries are available but students are encouraged to first try and intuit or remember the meaning of unknown words \pcite{mcdonald2016}. Another study drew a more moderate conclusion, recommending a balance between looking up words in a dictionary (to boost retention) but discouraging its excessive (to avoid lower reading speeds) \pcite{dictionaryimportance}. Dictionaries have been found to be particularly helpful to beginners but remain useful to all levels of foreign language student \pcite{dictionaryvalue}. And additional research suggests that whether a dictionary is monolingual, bilingual, or image based has less impact on learning outcomes than how frequently it is referenced \pcite{dictionarypitfalls, imagesdictionary, bilingual_dictionary}.

Finally, given that technology has a come a long way since leveled readers were first introduced, it should come as no surprise that some innovative modifications have been proposed. There is general consensus that listening to the audio transcription of a text while simultaneously reading it facilitates superior learning compared to reading the text on its own \pcite{Chang2015ImprovingRR}. While novel computer-assisted presentations of graded text such as interlinear reading and the diglot weave have been introduced in consumer language learning applications, research into their efficacy is inconclusive \pcite{hyplern_interlinear_reading, diglot_weave}.

\subsection{How can an LLM best be induced to follow these practices?}

With the need for leveled readers and some of their best practices established, how might a Large Language Model (LLM) be leveraged to create a high-quality leveled reading experience? Before diving into this question, it's worth pointing out that LLMs have been shown to outperform neural networks, machine learning frameworks, and other rules-based approaches at text simplification, making them the ideal tool to consider \pcite{feng2023sentence}. This begs the important–if uninteresting–question of which LLM exhibits the best performance at adjacent tasks. During a recent evaluation, Open AI's models received the highest scores across several benchmarks \pcite{kew2023bless} with GPT-4 standing out in particular \pcite{wu2024indepth} even when compared to models purpose-built for the task of sentence simplification \pcite{ai_human_taking_turns_creating_story}.

With the ideal LLM identified, how can it be leveraged for this task? While this question is innately subjective, recent research suggests that an LLM can, by dynamically generating the subsequent portions of a leveled reader in real-time, customize each passage to align with each student's current state of vocabulary acquisition. Where a traditional leveled reader has no capacity to adjust its text based on the amount of time between reading sessions, or which words the individual student finds difficult, an LLM can form the bedrock of such a system.

Adaptive Learning and Intelligent Tutoring Systems (ITS) have become incredibly sophisticated since their inception in the 1970s. Adaptive learning systems model a student's performance on past exercises to create new exercises (or in this case, text) at an "appropriate estimated level of difficulty for that particular student\footnote{quotations denote attribution of my own writing from a previous assignment.}" \cite{important_adaptive_learning_exercise_generation}.

This begs the question: how does a passive activity such as free reading generate the data necessary to create a model of a student's knowledge and/or performance? One option is to use dictionary lookup events as a proxy for a student's failure to understand that word or grammatical structure. To ground that in an example, if a student clicks on a word to present the tool-tip containing its definition, the ITS can add that word to the list of vocabulary that needs to be presented consistently throughout subsequent passages in the leveled reader. To complete this example, imagine the LLM is prompted to produce one hundred words of the leveled reader at a time, establishing continuity with the existing story, written at a level that facilitates ninety-eight percent vocabulary recognition for the reader, and presenting the words in a proverbial flashcard deck that are most in need of review. This suggestion is based on the finding that LLMs perform well on tasks that require maintaining continuity in stories that they produce across several prompts \pcite{controllable_story_generation}. The prompt to the LLM might resemble:

\blockquote{Examine the last one thousand words of text you have produced for this story. Please generate the next one hundred words of that story, emphasizing continuity and written at a level of complexity that is in line with the last one thousand words. This passage must contain the words in this list: [\textit{list of words that are due for review according to spaced repetition scheduler}]. If the preceding list was empty, you may slightly increase the complexity of this subsequent passage compared to the last one thousand words. If you have not generated any words of text for this story, provide an introduction for one of Aesop's Fables, written in very simple language that should be understood by a student learning English as a foreign language who only knows the 2,500 thousand most common words.}

Despite evidence that LLMs have degraded retrieval of information provided in the middle of a context window, input tokens are sufficiently cheap and input windows sufficiently large to provide not only the last thousand words of the story as input, but also the instructions above \pcite{liu2023lost}. As already mentioned, beginning with texts simplified to use the 2500 most common words in the target language strikes balance between comprehensibility and nuance \pcite{nation1992vocabulary}. This proposal is grounded in recent precedents that establish similar links between the stochastic output from an LLM and a traditional rules-based system such as spaced repetition. The Taiwanese government recently deployed a similar ITS across its public school system \pcite{taiwan_adaptive_testing}. Although safeguards still need to considered to prevent the LLM, like any stochastic system, from producing expletives, plagiarism, or other problematic output, if however infrequent \pcite{recent_story_generation_review}.
 
Another possibility is to use deep learning to model student knowledge rather that a flashcard deck. However, this approach, often referred to as Deep Knowledge Tracing \pcite{deep_knowledge_tracing}, has meaningful drawbacks, the most obvious being the challenge of implementing them \pcite{question_generation_adaptive_education, generative_information_retrieval} and the need to customize them for a specific domain \pcite{dkt_knowledge_tracing}. In addition, there is limited evidence that such a model provides meaningful improvement over a state-of-the-art (SOTA) spaced-repetition system \pcite{flashcard_scheduler_evolution}, and such a system is harder to interpret, making it harder to be used by teachers \pcite{deep_learning_knowledge_tracing}.

One advantage of Deep Knowledge Tracing is that it provides an ITS a way to model and balance what a student \textit{needs} to learn against what they \textit{want} to learn \pcite{llm_augmented_exercise_retrieval}. In the context of leveled reader generation, this could empower the student to solicit the plot to move in certain directions, adding a motivating element of interactivity. However, it's likely that this is achievable by modifying the prompt engineering of the LLM without introducing deep knowledge tracing.

In order to iterate and improve upon such an "ITS for leveled readers," it will be essential to establish an evaluation framework for the system's output. Some of the most popular frameworks for evaluating text simplification, besides human scoring, are SARI \pcite{xu-etal-2016-optimizing}, SAMSA \pcite{sulem-etal-2018-semantic}, BLEU, and BLESS \pcite{kew2023bless}.\footnote{Fully spelled out, those initialisms are as follows: System output Against References and against the Input sentence, Semantic Structural Analysis, Bilingual Evaluation Understudy, Benchmark for Lexical Substitution Semantics} Adopting one or several such evaluation frameworks are particularly important because of the fact that humans continue to outperform LLMs at sentence simplification by a significant margin. Without the objective validation of these frameworks, it will be difficult to prove that an LLM can be induced to create Leveled Readers at a high enough caliber to serve as useful curricula.

While providing audio transcriptions of the text generated by the LLM \pcite{Chang2015ImprovingRR} and integrating a dictionary into a user interface \pcite{mcdonald2016} are arguably as important as the implementation of the LLM itself, their implementation falls outside the scope of this section of the qualifier question.

\printbibliography{}

\end{document}